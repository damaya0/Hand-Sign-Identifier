# -*- coding: utf-8 -*-
"""Rock_Paper_Scissor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BBzEm8XitPhTxJsalWQFh9rkjP2cQsWv

## Download & Extract Rock-Paper-Scissor Datasets
"""

!mkdir ./tmp

"""Train Dataset"""

!wget --no-check-certificate \
    https://storage.googleapis.com/download.tensorflow.org/data/rps.zip \
    -O ./tmp/rps.zip

"""Validation Dataset"""

!wget --no-check-certificate \
    https://storage.googleapis.com/download.tensorflow.org/data/rps-test-set.zip \
    -O ./tmp/rps-test-set.zip

"""## Use Zipfile to extract the files"""

import zipfile
import os

def extract_file(src, dest):
  # opening the zip file in READ mode
  with zipfile.ZipFile(src, 'r') as zip:
      # extracting all the files
      print(f'Extracting all the files from {src}...')
      zip.extractall(dest)
      print('Done!')

extract_file(src='./tmp/rps.zip', dest='./data')
extract_file(src='./tmp/rps-test-set.zip', dest='./data')

def get_image_counts(parent_folder, dataset_name):
  rock_dir = os.path.join(parent_folder, 'rock')
  paper_dir = os.path.join(parent_folder, 'paper')
  scissors_dir = os.path.join(parent_folder, 'scissors')

  print(f'total {dataset_name} rock images: {len(os.listdir(rock_dir))}')
  print(f'total {dataset_name} paper images: {len(os.listdir(paper_dir))}')
  print(f'total {dataset_name} scissors images: {len(os.listdir(scissors_dir))}')

get_image_counts(parent_folder='./data/rps', dataset_name='training')

get_image_counts(parent_folder='./data/rps-test-set', dataset_name='testing')

"""# Training Pipeline Implementation

## Import Required Libraries
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

"""### 2.1. Visualize Data"""

for label in ['rock', 'paper', 'scissors']:
  im_folder = f'./data/rps/{label}'
  im_count = 2
  for im_name in  os.listdir(im_folder)[:im_count]:
      im_path = os.path.join(im_folder, im_name)
      img = Image.open(im_path).convert('RGB')
      img = np.asarray(img)
      # plt.title(f'Label: { y_test[i]}')
      plt.imshow(img)
      plt.show()
  print(img.shape)

"""# Use Image Data Generator to Pre-process and to Feed data to the training pipeline"""

from keras.preprocessing.image import ImageDataGenerator

TRAINING_DIR = "./data/rps/"
training_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
    )

VALIDATION_DIR = "./data/rps-test-set/"
validation_datagen = ImageDataGenerator(rescale = 1./255)

train_generator = training_datagen.flow_from_directory(
	TRAINING_DIR,
	target_size=(128, 128),
	class_mode='categorical',  # returns 2D one-hot encoded
  batch_size=64
)

validation_generator = validation_datagen.flow_from_directory(
	VALIDATION_DIR,
	target_size=(128, 128),
	class_mode='categorical',  # returns 2D one-hot encoded
  batch_size=64
)

"""# Create the Model"""

model = tf.keras.models.Sequential([
    # This is the first convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(128, 128, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),

    # The second convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    # The third convolution
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    # The fourth convolution block
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),

    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),

    # Output layer with Softmax activation.
    tf.keras.layers.Dense(3, activation='softmax')

])
model.summary()

"""## Class names order"""

class_names = sorted(os.listdir('/content/data/rps'))

"""## Define a suitable preprocessing function

"""

def im_preprocess(img_path, display=False):
  img = Image.open(img_path).convert('RGB')  # (300, 300, 3)
  newsize = (128, 128)
  img = img.resize(newsize)  # (128, 128, 3)
  img = np.asarray(img)
  img = img/255.  # Normalize images value from [0, 255] to [0, 1].
  if display:
    plt.imshow(img)
    plt.show()
  img = np.expand_dims(img, axis=0) # (1, 128, 128, 3)
  return img

"""## Predict before training."""

im_path = './data/rps/scissors/scissors01-004.png'
img = im_preprocess(img_path=im_path, display=True)

pred_b4_training = model.predict(img)
print(pred_b4_training)
print('\n Prediction before Training:', class_names[np.argmax(pred_b4_training)])

"""## Train the model.

### Define tensorboard_callback
"""

# Use tensorboard_callback for training.
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir="./logs")

model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),
             loss = 'categorical_crossentropy', metrics=keras.metrics.CategoricalAccuracy())

# Use tensorboard_callback for training.
hist = model.fit(train_generator, epochs = 25, validation_data = validation_generator, callbacks=[tensorboard_callback])

"""## Evaluate trained Model"""

print("Evaluate on test data")
results = model.evaluate(validation_generator, batch_size=128)
print("test loss, test acc:", results)

"""### Save Trained Model"""

model.save("rps_model.h5")

"""### Load Trained Model"""

trained_model = keras.models.load_model('rps_model.h5')

"""## Run Inference after training"""

im_path = '/content/data/rps-test-set/rock/testrock01-05.png'
img = im_preprocess(img_path=im_path, display=True)

pred_after_training = trained_model.predict(img)
print(pred_after_training)
print('\n Prediction after Training:', class_names[np.argmax(pred_after_training)])

im_path = '/content/data/rps-test-set/paper/testpaper01-07.png'
img = im_preprocess(img_path=im_path, display=True)

pred_after_training = trained_model.predict(img)
print(pred_after_training)
print('\n Prediction after Training:', class_names[np.argmax(pred_after_training)])

im_path = '/content/data/rps-test-set/scissors/testscissors01-10.png'
img = im_preprocess(img_path=im_path, display=True)

pred_after_training = trained_model.predict(img)
print(pred_after_training)
print('\n Prediction after Training:', class_names[np.argmax(pred_after_training)])

"""## Visualize training with tensorboard."""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir './logs'